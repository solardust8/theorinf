# Теория информации и кодирования. Лабораторная №1.

Задача настоящей лабораторной работы состоит в реализации кодека сжатия изображений, принцип которого основывается на применении арифметического кодирования к скрытому представлению изображения в латентном пространстве автоэнкодера.

Работу выполнил Домницкий Егор М4130.


# Архитектура автоэнкодера

Архитектуру автоэнкодера можно видеть на рисунке ниже.

В базовую архитектуру преподавателя были добавлены следующие элементы:

1. **Batch Normalization**: батчевая нормализация позволяет нормализовать пространство каналов (признаков/фильтров) по батчу, тем самым уменьшая смещения между распределениями после сверток. Это приводит к уменьшению дисперии итогового вывода модели, а так же действует как фактор регуляризации. 
2. **Residual blocks**: "остаточные блоки" позволяют увеличить глубину модели и количество фильтров (тем самым увеличивая количество и качество извлекаемых признаков), при этом не вредя обучаемости модели. Дело в том, что при увеличнии глубины модели градиент начинает затухать при обратном проходе, приводя к тому, что начальные слои совсем мало обучаются - **skip connections** в остаточных блоках позволяет избежать этой проблемы, передавая через себя градиент к предыдущему блоку. 

## Результат 

На настоящих демонстрациях можно видеть результат работы кодека сжатия (для сравнения с начальным результатом перейдите по [ссылке](https://ctlab.itmo.ru/gitlab/eabelyaev/cnnimagecodec)) 


## Запуск

Код простого тренировочного цикла и необходимые параметры смотри в файле `src/trainig.py`. 
Полный процесс обучения можно посмотреть в ноутбуке  `notebooks/RAE_Training.ipynb`.

Исходный код арифметического кодека `src/codec_cpp/`

Код модели `src/ResAE.py`.

Для простоuj запуска с целью получения вывода `python ready_model_demo.py`

