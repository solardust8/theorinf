# Теория информации и кодирования. Лабораторная №1.

Задача настоящей лабораторной работы состоит в реализации кодека сжатия изображений, принцип которого основывается на применении арифметического кодирования к скрытому представлению изображения в латентном пространстве автоэнкодера.

Работу выполнил Домницкий Егор М4130.


# Архитектура автоэнкодера

В рамках настоящей работы было реализовано 2 модели архитектуры автоэнкодер: **Residual AE v1** и **Residual AE v2**.

Архитектуры автоэнкодеров можно видеть на рисунке ниже.
![](/misc/architecture.png)

В **Residual AE v1** в базовую архитектуру преподавателя были добавлены следующие элементы:

1. **Batch Normalization**: батчевая нормализация позволяет нормализовать пространство каналов (признаков/фильтров) по батчу, тем самым уменьшая смещения между распределениями после сверток. Это приводит к уменьшению дисперии итогового вывода модели, а так же действует как фактор регуляризации. 
2. **Residual blocks**: "остаточные блоки" позволяют увеличить глубину модели и количество фильтров (тем самым увеличивая количество и качество извлекаемых признаков), при этом не вредя обучаемости модели. Дело в том, что при увеличении глубины модели градиент начинает затухать при обратном проходе, приводя к тому, что начальные слои совсем мало обучаются - **skip connections** в остаточных блоках позволяет избежать этой проблемы, передавая через себя градиент к предыдущему блоку. 

Тем не менее, как можно будет видеть в разделе **Результат**, для выходных изображений первой версии характерны крупные "паттерны", а так же артефактные черные "битые" пиксели. 

Артефакты появлялись из-за того, что количество фильтров (глубина модели) было резко увеличино при неотрицательной функции активации (ReLU >= 0) - что приводило к выбросам в скрытых слоях модели, а при отсутствии сигмодилаьного преобразования (Sigmoid) в конце декодера - к выбросам на выходном изображении. 

Крупные "паттерны" в целом харакетры для выходов транспонированной свертки (т-свертки), и происходит это из-за того, что размер ядра т-свертки не кратен величине ее шага.

В **Residual AE v2** указанные недостатки были адресованы следующими модификациями:

1. **Mish activation**: был выбрана в качестве функции активации. [Ссылка на статью](https://arxiv.org/pdf/1908.08681). Сравнение выходов функций активации и их вид представлен на рисунке ниже ![](/misc/relu_mish.png) Данная функция активации показала более высокий результат на бенчмарках CIFAR-10 и ImageNet. Ее отличительными качествами, которые полезны для улучшения качества автоэнкодера и устранения артефактов, являются ее сглаживающая способность, а так же способность сохранять небольшие отрицательные изменения весов, что положительно сказывается на течении градиента.
2. **Добавление сигмоиды, уменьшение глубины энкодера и декодера**: количество фильтров было уменьшено для лучшей обучаемости начальных слоев (сигмоида на выходе декодера замедляет сходимость). 2 ступени даунсемплинга с ядром к=3 были заменены 1 ступенью с к=5.
3. **Т-Свертки с четным ядром**: для того, чтобы как можно больше невелировать эффект мозаичности на выходе декодера был применен трюк, заключающийся в использовании Т-сверток с четным размером ядра (кратным шагу=2 при апсемплинге скрытого представления).



## Результат 

На настоящих демонстрациях можно видеть результат работы кодека сжатия ([ссылка на базовый кодек](https://ctlab.itmo.ru/gitlab/eabelyaev/cnnimagecodec)) 

Для всех тестов применялись модели ResAE v1-2, обученные 200 эпох с параметром b=3.

Для сравнений использовалась базовая модель, обученная 300 эпох с параметром b=3.

Сравнение с базовым кодеком осуществляется при b=1,2,3.



![](/misc/diff.png)
![](/misc/diff1.png)
![](/misc/diff2.png)
![](/misc/diff3.png)
![](/misc/findiff.jpg)


## Запуск

Код простого тренировочного цикла и необходимые параметры смотри в файле `src/trainig.py`. 
Полный процесс обучения и код модели первой версии можно посмотреть в ноутбуке  `notebooks/RAE_Training.ipynb`.

Исходный код арифметического кодека `src/codec_cpp/`

Код модели версии 2 и базового кодека `src/ResAE.py`.

Для простого запуска с целью получения вывода `python ready_model_demo.py`

