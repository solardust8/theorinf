# Теория информации и кодирования. Лабораторная №1.

Задача настоящей лабораторной работы состоит в реализации кодека сжатия изображений, принцип которого основывается на применении арифметического кодирования к скрытому представлению изображения в латентном пространстве автоэнкодера.

Работу выполнил Домницкий Егор М4130.


# Архитектура автоэнкодера

Архитектуру автоэнкодера можно видеть на рисунке ниже.

В базовую архитектуру преподавателя были добавлены следующие элементы:

1. **Batch Normalization**: батчевая нормализация позволяет нормализовать пространство каналов (признаков/фильтров) по батчу, тем самым уменьшая смещения между распределениями после сверток. Это приводит к уменьшению дисперии итогового вывода модели, а так же действует как фактор регуляризации. 
2. **Residual blocks**: "остаточные блоки" позволяют увеличить глубину модели и количество фильтров (тем самым увеличивая количество и качество извлекаемых признаков), при этом не вредя обучаемости модели. Дело в том, что при увеличнии глубины модели градиент начинает затухать при обратном проходе, приводя к тому, что начальные слои совсем мало обучаются - **skip connections** в остаточных блоках позволяет избежать этой проблемы, передавая через себя градиент к предыдущему блоку. 

![](/misc/architecture.png)


## Результат 

На настоящих демонстрациях можно видеть результат работы кодека сжатия (для сравнения с начальным результатом перейдите по [ссылке](https://ctlab.itmo.ru/gitlab/eabelyaev/cnnimagecodec)) 

Для всех тестов применялась модель, обученная с параметром b=3.


**Квантование с b=2**

![](/misc/output.jpg)

**Квантование с b=3**

![](/misc/output2.jpg)

**Квантование с b=1**

![](/misc/output3.jpg)


## Сравнение

**Сравненеие с базовым кодеком при  b=2**

![](/misc/diff.png)

Предложенное решение не сильно уступает по значению BPP, тем не менее, выигрывая в качестве картинки (визуальная оценка восприятия и показатель PSNR).

Из-за природы архитектуры автоэнкодера (а именно из-за транспонированных сверток на стадии декодирования) - на изображении с кванотованием можно различить артефакты (рябь, повторяющиеся паттерны). Это же свойственно и базововму решению, однако в реализованной модели при b=2 менее заметно.

## Запуск

Код простого тренировочного цикла и необходимые параметры смотри в файле `src/trainig.py`. 
Полный процесс обучения можно посмотреть в ноутбуке  `notebooks/RAE_Training.ipynb`.

Исходный код арифметического кодека `src/codec_cpp/`

Код модели `src/ResAE.py`.

Для простого запуска с целью получения вывода `python ready_model_demo.py`

